{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fs_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fookseng/LSTM/blob/main/fs_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4PYRMwNAI3H"
      },
      "source": [
        "Perform MSE for T-1 and T."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEtz6i4PHaWs"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "from tensorflow.keras.models import Sequential, model_from_json, load_model\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Activation, Flatten, LeakyReLU, ReLU, PReLU, Dropout, BatchNormalization, LSTM\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Nadam, Adadelta \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from PIL import Image as im\n",
        "from keras.preprocessing.image import image\n",
        "import shutil\n",
        "import imageio\n",
        "from numpy import array\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTXh5UMpHj6T",
        "outputId": "9f04f733-9233-49a4-f6f9-d2d540865701"
      },
      "source": [
        "# Check tensorflow version\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MldnYJFLHl6M",
        "outputId": "9d305caf-cbf6-4b93-cb48-7db9f3f93cb4"
      },
      "source": [
        "# Mount Google Drive to access data\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfxZdJe9KtjV"
      },
      "source": [
        "# *Functions*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DxLG5dkKwGt"
      },
      "source": [
        "def create_data(x, y):\n",
        "  # Pixel dataset\n",
        "  images_T1_2019 = np.load(path +'/image_array_1_2019.npy')\n",
        "  images_T1_2018 = np.load(path +'/image_array_1_2018.npy')\n",
        "  images_T1_2011_2017 = np.load(path +'/image_array_1_2011_2017.npy')\n",
        "  images_T_2019 = np.load(path +'/image_array_2_2019.npy')\n",
        "  images_T_2018 = np.load(path +'/image_array_2_2018.npy')\n",
        "  images_T_2011_2017 = np.load(path +'/image_array_2_2011_2017.npy')\n",
        "  tide_T_2019 = np.load(path +'/delta_tide_array_2_2019.npy')\n",
        "  tide_T_2018 = np.load(path +'/delta_tide_array_2_2018.npy')\n",
        "  tide_T_2011_2017 = np.load(path +'/delta_tide_array_2_2011_2017.npy')\n",
        "\n",
        "  print(\"Creating dataset on point:\", x,\",\", y)\n",
        "  for i in range(tide_T_2011_2017.size):\n",
        "      pixel_data_train1.append(images_T1_2011_2017[i][y][x])\n",
        "      pixel_data_train2.append(images_T_2011_2017[i][y][x])\n",
        "  for i in range(tide_T_2019.size):\n",
        "      pixel_data_train1.append(images_T1_2019[i][y][x])\n",
        "      pixel_data_train2.append(images_T_2019[i][y][x])\n",
        "  for i in range(tide_T_2018.size):\n",
        "      pixel_data_test1.append(images_T1_2018[i][y][x])\n",
        "      pixel_data_test2.append(images_T_2018[i][y][x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J4l8SxATFGb"
      },
      "source": [
        "# *Main function*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zArOFvnTIrV",
        "outputId": "f09a2046-0d5e-4f1f-dc42-baf9257dcf31"
      },
      "source": [
        "if __name__ == '__main__':\n",
        " \n",
        "  path = '/content/gdrive/Shareddrives/namr - water quality forecast/1005data_OutletOnly(8x12)/TSS/continuous_for_3_yearly'\n",
        "  x_pos, y_pos = 2, 2\n",
        "  # Define some variables.\n",
        "  pixel_data_train1 = []\n",
        "  pixel_data_train2 = []\n",
        "  pixel_data_test1 = []\n",
        "  pixel_data_test2 = []\n",
        "  ### Create data and save as pandas DataFrame\n",
        "  m = create_data(x_pos, y_pos)\n",
        "  \n",
        "  mse_test = mean_squared_error(pixel_data_test1, pixel_data_test2)\n",
        "  mse_train = mean_squared_error(pixel_data_train1, pixel_data_train2)\n",
        " \n",
        "  print(\"LOSS test: \", mse_test)\n",
        "  print(\"LOSS train: \", mse_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dataset on point: 2 , 2\n",
            "LOSS test:  0.42221352\n",
            "LOSS train:  0.42603913\n"
          ]
        }
      ]
    }
  ]
}